{"cells":[{"cell_type":"markdown","metadata":{"id":"AzVnzFxO5PVh"},"source":["# Price Momentum Strategy\n","\n","The crux of this strat is the hypothesis that historically well performing stocks will tend to do so in the future as well.\n","\n","The criteria then falls on finding the reliable standard by which to find these stocks.\n","\n","In case of dollar neutral stocks, the point is also to determine whether wealth allocation into low performing stock through shorting is favourable or not, as well."]},{"cell_type":"markdown","metadata":{"id":"004135b3"},"source":["This cell imports all the necessary libraries for the price momentum strategy, including libraries for data manipulation (pandas, numpy), plotting (matplotlib, seaborn), date calculations (dateutil.relativedelta, datetime), fetching financial data (yfinance), interacting with Google Sheets (google.colab.sheets), and portfolio optimization (scipy.cluster.hierarchy, scipy.spatial.distance, pypfopt)."]},{"cell_type":"code","source":["pip install PyPortfolioOpt\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lYEfWBCQz9xB","executionInfo":{"status":"ok","timestamp":1750867180642,"user_tz":-330,"elapsed":6651,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"}},"outputId":"858cee29-394a-4e84-decd-92468034a18d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting PyPortfolioOpt\n","  Downloading pyportfolioopt-1.5.6-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: cvxpy>=1.1.19 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (1.6.6)\n","Collecting ecos<3.0.0,>=2.0.14 (from PyPortfolioOpt)\n","  Downloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (2.0.2)\n","Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (2.2.2)\n","Requirement already satisfied: plotly<6.0.0,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (5.24.1)\n","Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.11/dist-packages (from PyPortfolioOpt) (1.15.3)\n","Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (1.0.4)\n","Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (0.11.1)\n","Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.11/dist-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (3.2.7.post2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2025.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly<6.0.0,>=5.0.0->PyPortfolioOpt) (9.1.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly<6.0.0,>=5.0.0->PyPortfolioOpt) (24.2)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.11/dist-packages (from clarabel>=0.5.0->cvxpy>=1.1.19->PyPortfolioOpt) (1.17.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (75.2.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (1.5.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19->PyPortfolioOpt) (1.17.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi->clarabel>=0.5.0->cvxpy>=1.1.19->PyPortfolioOpt) (2.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (3.0.2)\n","Downloading pyportfolioopt-1.5.6-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.1/220.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ecos, PyPortfolioOpt\n","Successfully installed PyPortfolioOpt-1.5.6 ecos-2.0.14\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2235,"status":"ok","timestamp":1750867255339,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"Wp5fXZt142q5"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib as plt\n","import seaborn as sb\n","from dateutil.relativedelta import relativedelta\n","import yfinance as yf\n","pd.set_option('display.max_rows', None)\n","from datetime import datetime\n","from math import log\n","from google.colab import sheets\n","pd.set_option('future.no_silent_downcasting', True)\n","from scipy.cluster.hierarchy import linkage, dendrogram\n","from scipy.spatial.distance import squareform\n","from pypfopt import HRPOpt"]},{"cell_type":"markdown","metadata":{"id":"4becfc05"},"source":["This cell defines the list of stock tickers that will be used in the analysis and sets the holding and skip periods for the strategy in months."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1750867258505,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"WtCg3mtFxZLK"},"outputs":[],"source":["tickers = [\"ADANIPORTS.NS\", \"ASIANPAINT.NS\", \"AXISBANK.NS\", \"BAJAJ-AUTO.NS\", \"BAJFINANCE.NS\",\n","    \"BAJAJFINSV.NS\", \"BPCL.NS\", \"BHARTIARTL.NS\", \"BRITANNIA.NS\", \"CIPLA.NS\",\n","    \"COALINDIA.NS\", \"DIVISLAB.NS\", \"DRREDDY.NS\", \"EICHERMOT.NS\", \"GRASIM.NS\",\n","    \"HCLTECH.NS\", \"HDFCBANK.NS\", \"HDFCLIFE.NS\", \"HEROMOTOCO.NS\", \"HINDALCO.NS\",\n","    \"HINDUNILVR.NS\", \"ICICIBANK.NS\", \"ITC.NS\", \"INDUSINDBK.NS\", \"INFY.NS\",\n","    \"JSWSTEEL.NS\", \"KOTAKBANK.NS\", \"LT.NS\", \"M&M.NS\", \"MARUTI.NS\",\n","    \"NTPC.NS\", \"NESTLEIND.NS\", \"ONGC.NS\", \"POWERGRID.NS\", \"RELIANCE.NS\",\n","    \"SBILIFE.NS\", \"SHREECEM.NS\", \"SBIN.NS\", \"SUNPHARMA.NS\", \"TCS.NS\",\n","    \"TATACONSUM.NS\", \"TATAMOTORS.NS\", \"TATASTEEL.NS\", \"TECHM.NS\", \"TITAN.NS\",\n","    \"ULTRACEMCO.NS\", \"UPL.NS\", \"WIPRO.NS\", \"ZEEL.NS\"]\n","\n","holding_period = 1\n","skip_period = 1"]},{"cell_type":"markdown","metadata":{"id":"c057159e"},"source":["This cell defines three functions to calculate different return metrics for a given ticker over a specified period:\n","- `cum_returns`: Calculates the cumulative returns.\n","- `mean_returns`: Calculates the mean monthly returns.\n","- `risk_adj_returns`: Calculates the risk-adjusted returns (Sharpe Ratio).\n","It then initializes an empty DataFrame `return_params` to store these calculated metrics for each ticker and date, and finally populates this DataFrame by iterating through the defined tickers and a range of rolling dates."]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":348720,"status":"ok","timestamp":1750867609360,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"FDnMyfYD5Onx"},"outputs":[],"source":["# Define a function to calculate cumulative returns for a given ticker over a specified period\n","def cum_returns(ticker, form_period, skip_period, rolling_date, holding_period):\n","  start = (datetime.today() - relativedelta(months= form_period+rolling_date+holding_period)).strftime('%Y-%m-%d')\n","  end = (datetime.today()-relativedelta(months = rolling_date-skip_period+holding_period)).strftime('%Y-%m-%d')\n","  price_action = yf.download(ticker, start, end, auto_adjust= True, progress=False)\n","  price_df = pd.DataFrame(price_action[('Close', ticker)])\n","  price_df.rename(columns = {ticker: 'Close'}, inplace = True)\n","\n","  P_S = price_df.iat[-2, 0]\n","  P_ST = price_df.iat[0, 0]\n","  log_returns = (P_S/P_ST-1)*100\n","\n","  return log_returns\n","\n","def mean_returns(ticker, form_period, skip_period, rolling_date, holding_period):\n","  start = (datetime.today() - relativedelta(months= form_period+rolling_date+holding_period)).strftime('%Y-%m-%d')\n","  end = (datetime.today()-relativedelta(months = rolling_date-skip_period+holding_period)).strftime('%Y-%m-%d')\n","  price_action = yf.download(ticker, start, end, interval = '1mo', auto_adjust= True, progress=False)\n","\n","  returns = np.log(price_action['Close'] / price_action['Close'].shift(1)).dropna()*100\n","  returns.rename(columns = {ticker: 'Returns'}, inplace = True)\n","\n","  return returns['Returns'].mean()\n","\n","def risk_adj_returns(ticker, form_period, skip_period, rolling_date, holding_period):\n","  start = (datetime.today() - relativedelta(months= form_period+rolling_date+holding_period)).strftime('%Y-%m-%d')\n","  end = (datetime.today()-relativedelta(months = rolling_date-skip_period+holding_period)).strftime('%Y-%m-%d')\n","  price_action = yf.download(ticker, start, end, interval = '1mo', auto_adjust= True, progress=False)\n","\n","  returns = np.log(price_action['Close'] / price_action['Close'].shift(1)).dropna()\n","  returns.rename(columns = {ticker: 'Returns'}, inplace = True)\n","  mean_returns = returns['Returns'].mean()\n","  std_returns = returns['Returns'].std()\n","\n","  return mean_returns/std_returns\n","\n","def volatility_trend(ticker, form_period, skip_period, rolling_date, holding_period):\n","    start = (datetime.today() - relativedelta(months=form_period + rolling_date + holding_period)).strftime('%Y-%m-%d')\n","    mid = (datetime.today() - relativedelta(months=form_period//2 + rolling_date + holding_period)).strftime('%Y-%m-%d')\n","    end = (datetime.today() - relativedelta(months=rolling_date - skip_period + holding_period)).strftime('%Y-%m-%d')\n","\n","    data = yf.download(ticker, start=start, end=end, interval='1mo', auto_adjust=True, progress=False)['Close'].dropna()\n","    if len(data) < 4:\n","        return 0\n","\n","    returns = np.log(data / data.shift(1)).dropna()\n","    half = len(returns) // 2\n","    first_half_vol = returns.iloc[:half].std()\n","    second_half_vol = returns.iloc[half:].std()\n","    #print(first_half_vol, second_half_vol)\n","    vol_val = ((second_half_vol - first_half_vol) / first_half_vol) * 100 if first_half_vol.any() != 0 else 0\n","    return vol_val.values\n","\n","\n","return_params = pd.DataFrame(columns = ['Date','Ticker', 'Cumulative Returns', 'Mean Returns', 'Risk Adjusted Returns', 'Volatility Trend'])\n","\n","def return_params_df(tickers, form_period, skip_period, rolling_date, holding_period):\n","  for ticker in tickers:\n","    cum_returns_val = cum_returns(ticker, form_period, skip_period, rolling_date, holding_period)\n","    mean_returns_val = mean_returns(ticker, form_period, skip_period, rolling_date, holding_period)\n","    risk_adj_returns_val = risk_adj_returns(ticker, form_period, skip_period, rolling_date, holding_period)\n","    volatility_trend_val = volatility_trend(ticker, form_period, skip_period, rolling_date, holding_period)\n","\n","    return_params.loc[len(return_params.index)] = [(datetime.today()-relativedelta(months = rolling_date+skip_period+holding_period)).strftime('%Y-%m-%d'),\n","                                                   ticker, cum_returns_val, mean_returns_val, risk_adj_returns_val, volatility_trend_val]\n","  return return_params\n","\n","for rolling_date in range(12):\n","  return_params_df(tickers, 12, 1, rolling_date, 1)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fdde6b03"},"source":["This cell iterates through the rolling dates and identifies the top and bottom 5 performing stocks based on the calculated cumulative returns, mean returns, and risk-adjusted returns from the `return_params` DataFrame. It then prints the tickers of the top and bottom performing stocks based on cumulative returns for the last rolling date."]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":161,"status":"ok","timestamp":1750867609516,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"b1xGAJytUZV1"},"outputs":[],"source":["# Iterate through rolling dates to find top and bottom performing stocks based on different metrics\n","for rolling_date in range(12):\n","  top_by_cumret = return_params[return_params['Date'] == (datetime.today()-relativedelta(months = rolling_date+skip_period+holding_period)).strftime('%Y-%m-%d')].sort_values(by = 'Cumulative Returns', ascending = False).head()\n","  top_by_meanret = return_params[return_params['Date'] == (datetime.today()-relativedelta(months = rolling_date+skip_period+holding_period)).strftime('%Y-%m-%d')].sort_values(by = 'Mean Returns', ascending = False).head()\n","  top_by_radret = return_params[return_params['Date'] == (datetime.today()-relativedelta(months = rolling_date+skip_period+holding_period)).strftime('%Y-%m-%d')].sort_values(by = 'Risk Adjusted Returns', ascending = False).head()\n","  top_by_voltrend = return_params[return_params['Date'] == (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y-%m-%d')].sort_values(by = 'Volatility Trend', ascending = False).head()\n","\n","  bottom_by_cumret = return_params[return_params['Date'] == (datetime.today()-relativedelta(months = rolling_date+skip_period+holding_period)).strftime('%Y-%m-%d')].sort_values(by = 'Cumulative Returns', ascending = True).head()\n","  bottom_by_meanret = return_params[return_params['Date'] == (datetime.today()-relativedelta(months = rolling_date+skip_period+holding_period)).strftime('%Y-%m-%d')].sort_values(by = 'Mean Returns', ascending = True).head()\n","  bottom_by_radret = return_params[return_params['Date'] == (datetime.today()-relativedelta(months = rolling_date+skip_period+holding_period)).strftime('%Y-%m-%d')].sort_values(by = 'Risk Adjusted Returns', ascending = True).head()\n","  bottom_by_voltrend = return_params[return_params['Date'] == (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y-%m-%d')].sort_values(by = 'Volatility Trend', ascending = True).head()\n"]},{"cell_type":"markdown","metadata":{"id":"adad93a2"},"source":["This cell defines two functions:\n","- `calculate_weights`: Calculates portfolio weights based on the inverse volatility of each stock.\n","- `backtest_cum_returns`: Calculates the backtested cumulative returns for a portfolio of stocks using the inverse volatility weighting scheme.\n","It also initializes an `initial_cap` variable, although it is not currently used in the provided code."]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":38,"status":"ok","timestamp":1750867609557,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"iSeMwyOtelKm"},"outputs":[],"source":["initial_cap =10000\n","\n","def calculate_weights(tickers, form_period, skip_period, rolling_date, holding_period):\n","  weights = np.array([])\n","  for ticker in tickers:\n","    start = (datetime.today() - relativedelta(months= form_period+rolling_date+holding_period)).strftime('%Y-%m-%d')\n","    end = (datetime.today()-relativedelta(months = rolling_date-skip_period-holding_period)).strftime('%Y-%m-%d')\n","    price_action = yf.download(ticker, start, end, interval = '1mo', auto_adjust= True, progress=False)\n","    price_df = pd.DataFrame(price_action[('Close', ticker)])\n","\n","    returns = np.log(price_action['Close'] / price_action['Close'].shift(1)).dropna()\n","    returns.rename(columns = {ticker: 'Returns'}, inplace = True)\n","    std_returns = returns['Returns'].std()\n","\n","    weights = np.append(weights, 1/std_returns)\n","  weight_n = weights/sum(weights)\n","  return weight_n\n","\n","def backtest_cum_returns(tickers,form_period, skip_period, rolling_date, holding_period):\n","  returns = []\n","  for ticker in tickers:\n","    start = (datetime.today() - relativedelta(months= skip_period+rolling_date+holding_period)).strftime('%Y-%m-%d')\n","    end = (datetime.today() - relativedelta(months= rolling_date+skip_period)).strftime('%Y-%m-%d')\n","    price_action = yf.download(ticker, start, end, auto_adjust= True, progress=False)\n","    price_df = pd.DataFrame(price_action[('Close', ticker)])\n","    returns.append((price_df.iat[-1, 0]/price_df.iat[0, 0]-1)*100)\n","  return sum(calculate_weights(tickers, 12, 1, rolling_date, 1)*returns)"]},{"cell_type":"markdown","metadata":{"id":"sB2dcl2bSi7q"},"source":["# Create trade sheet using cumulative returns"]},{"cell_type":"markdown","metadata":{"id":"3efb3f12"},"source":["This cell creates a DataFrame `trades_sheet_df` to record the trade details for a long-only strategy based on cumulative returns. It iterates through rolling dates, selects the top performing stocks based on cumulative returns, calculates their weights using the `calculate_weights` function, and then records trade information such as buy/sell prices, returns, drawdown, upside, and weights for each selected stock."]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":69819,"status":"ok","timestamp":1750868525561,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"nRwFy5eXSiBq"},"outputs":[],"source":["#Create trade sheet using cumulative returns\n","trades_sheet_df = pd.DataFrame(columns = ['Year','Month','stock','buy','sell', 'drawdown', 'upside', 'Monthly_Return', 'Cumulative_return', 'Mean_Monthly_Return', 'Monthly_Volatility', 'Risk_Adjusted_Mean_Return', 'Weight_norm'])\n","for rolling_date in range(12):\n","  year = (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y')\n","  month = (datetime.today() - relativedelta(months= skip_period+rolling_date)).strftime('%m')\n","\n","  stocks = return_params[return_params['Date'] == (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y-%m-%d')].sort_values(by = 'Cumulative Returns', ascending = False).head()['Ticker'].values\n","  weight = calculate_weights(stocks, 12, 1, rolling_date, 1)\n","  weights_df = pd.DataFrame(columns = ['Ticker','Weight'])\n","\n","  for i in range(len(stocks)):\n","    weights_df.loc[len(weights_df.index)] = [stocks[i], weight[i]]\n","\n","  for stock in stocks:\n","    if weight.all() > 0:\n","      position = 'Buy'\n","    else:\n","      position = 'Sell' #Safeguard, doesn't function in long only strat\n","\n","    price_data = yf.download(stock, (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y-%m-%d'),\n","                      end = (datetime.today() - relativedelta(months= skip_period+rolling_date)).strftime('%Y-%m-%d'),\n","                      auto_adjust= True, progress=False)\n","\n","    weight_norm = weights_df.loc[weights_df['Ticker'] == stock, 'Weight']\n","    drawdown = (1+price_data['Close'].pct_change()).cumprod()/((1+price_data['Close'].pct_change()).cumprod()).cummax()-1\n","    upside = (1+price_data['Close'].pct_change()).max()\n","    buy = price_data.iloc[0,0]\n","    sell = price_data.iloc[-1,0]\n","    monthly_return = log(price_data.iat[-1, 0]/price_data.iat[0, 0])*100\n","    cumulative_return = cum_returns(stock, 12, 1, rolling_date, 1)\n","    mean_monthly_return = mean_returns(stock, 12, 1, rolling_date, 1)\n","    monthly_volatility = 1/risk_adj_returns(stock, 12, 1, rolling_date, 1)*mean_monthly_return # This is not monthly volatility\n","    risk_adj_mean_return = risk_adj_returns(stock, 12, 1, rolling_date,1)\n","\n","    trades_sheet_df.loc[len(trades_sheet_df.index)] = [year, month, stock, buy, sell, drawdown[stock].min(), upside[stock].max(), monthly_return, cumulative_return, mean_monthly_return, monthly_volatility, risk_adj_mean_return, weight_norm.values[0]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UB9ocW955ki8"},"outputs":[],"source":["# Commented out code to create an interactive sheet for cumulative returns trades\n","# This is likely commented out because the sheet has already been generated\n","#sheet = sheets.InteractiveSheet(title = 'Trade Sheet Based on Cumulative Returns',df=trades_sheet_df)"]},{"cell_type":"markdown","metadata":{"id":"295ad46c"},"source":["This cell creates a DataFrame `trades_sheet_df_m` to record the trade details for a long-only strategy based on mean returns. Similar to the cumulative returns tradesheet, it iterates through rolling dates, selects the top performing stocks based on mean returns, calculates their weights, and records trade information."]},{"cell_type":"markdown","metadata":{"id":"YViAJQuhSaRF"},"source":["# Create trade sheet using mean returns"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":51697,"status":"ok","timestamp":1750868577279,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"KuOgbeWxRzst"},"outputs":[],"source":["#Create trade sheet using mean returns\n","trades_sheet_df_m = pd.DataFrame(columns = ['Year','Month','Position','stock','buy','sell', 'drawdown', 'upside', 'Monthly_Return', 'Cumulative_return', 'Mean_Monthly_Return', 'Monthly_Volatility', 'Risk_Adjusted_Mean_Return', 'Weight_norm'])\n","for rolling_date in range(12):\n","\n","  year = (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y')\n","  month = (datetime.today() - relativedelta(months= skip_period+rolling_date)).strftime('%m')\n","  stocks = return_params[return_params['Date'] == (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y-%m-%d')].sort_values(by = 'Mean Returns', ascending = False).head()['Ticker'].values\n","\n","  weight = calculate_weights(stocks, 12, 1, rolling_date, 1)\n","\n","  weights_df = pd.DataFrame(columns = ['Ticker','Weight'])\n","\n","  for i in range(len(stocks)):\n","    weights_df.loc[len(weights_df.index)] = [stocks[i], weight[i]]\n","\n","  for stock in stocks:\n","\n","    if weight.all() > 0:\n","      position = 'Buy'\n","    else:\n","      position = 'Sell' #Safeguard, doesn't function in long only strat\n","\n","    price_data = yf.download(stock, (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y-%m-%d'),\n","                      end = (datetime.today() - relativedelta(months= skip_period+rolling_date)).strftime('%Y-%m-%d'),\n","                      auto_adjust= True, progress=False)\n","    weight_norm = weights_df.loc[weights_df['Ticker'] == stock, 'Weight']\n","\n","    drawdown = (1+price_data['Close'].pct_change()).cumprod()/((1+price_data['Close'].pct_change()).cumprod()).cummax()-1\n","    upside = (1+price_data['Close'].pct_change()).max()\n","    buy = price_data.iloc[0,0]\n","    sell = price_data.iloc[-1,0]\n","    monthly_return = log(price_data.iat[-1, 0]/price_data.iat[0, 0])*100\n","    cumulative_return = cum_returns(stock, 12, 1, rolling_date, 1)\n","    mean_monthly_return = mean_returns(stock, 12, 1, rolling_date, 1)\n","    monthly_volatility = 1/risk_adj_returns(stock, 12, 1, rolling_date, 1)*mean_monthly_return # This is not monthly volatility\n","    risk_adj_mean_return = risk_adj_returns(stock, 12, 1, rolling_date,1)\n","\n","    trades_sheet_df_m.loc[len(trades_sheet_df_m.index)] = [year, month,position, stock, buy, sell, drawdown[stock].min(), upside[stock].max(), monthly_return, cumulative_return, mean_monthly_return, monthly_volatility, risk_adj_mean_return, weight_norm.values[0]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ahwC3enKSPdw"},"outputs":[],"source":["# Commented out code to create an interactive sheet for mean returns trades\n","# This is likely commented out because the sheet has already been generated\n","#sheet = sheets.InteractiveSheet(title = 'Trade Sheet Based on Mean Returns',df=trades_sheet_df_m)"]},{"cell_type":"markdown","metadata":{"id":"mq7yOQE6otnI"},"source":["# Create trade sheet using risk adjusted returns"]},{"cell_type":"markdown","metadata":{"id":"f6544b93"},"source":["This cell creates a DataFrame `trades_sheet_df_r` to record the trade details for a long-only strategy based on risk-adjusted returns. It iterates through rolling dates, selects the top performing stocks based on risk-adjusted returns, calculates their weights, and records trade information."]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":63494,"status":"ok","timestamp":1750868640788,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"GKvkOewKjOxv"},"outputs":[],"source":["trades_sheet_df_r = pd.DataFrame(columns = ['Year','Month','Position','stock','buy','sell', 'drawdown', 'upside', 'Monthly_Return', 'Cumulative_return', 'Mean_Monthly_Return', 'Monthly_Volatility', 'Risk_Adjusted_Mean_Return', 'Weight_norm'])\n","for rolling_date in range(12):\n","\n","  year = (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y')\n","  month = (datetime.today() - relativedelta(months= skip_period+rolling_date)).strftime('%m')\n","  stocks = return_params[return_params['Date'] == (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y-%m-%d')].sort_values(by = 'Risk Adjusted Returns', ascending = False).head()['Ticker'].values\n","  weight = calculate_weights(stocks, 12, 1, rolling_date, 1)\n","  weights_df = pd.DataFrame(columns = ['Ticker','Weight'])\n","\n","  for i in range(len(stocks)):\n","    weights_df.loc[len(weights_df.index)] = [stocks[i], weight[i]]\n","\n","  for stock in stocks:\n","    if weight.all() > 0:\n","      position = 'Buy'\n","    else:\n","      position = 'Sell' #Safeguard, doesn't function in long only strat\n","\n","    price_data = yf.download(stock, (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y-%m-%d'),\n","                      end = (datetime.today() - relativedelta(months= skip_period+rolling_date)).strftime('%Y-%m-%d'),\n","                      auto_adjust= True, progress=False)\n","    weight_norm = weights_df.loc[weights_df['Ticker'] == stock, 'Weight']\n","    drawdown = (1+price_data['Close'].pct_change()).cumprod()/((1+price_data['Close'].pct_change()).cumprod()).cummax()-1\n","    upside = (1+price_data['Close'].pct_change()).max()\n","    buy = price_data.iloc[0,0]\n","    sell = price_data.iloc[-1,0]\n","    monthly_return = log(price_data.iat[-1, 0]/price_data.iat[0, 0])*100\n","    cumulative_return = cum_returns(stock, 12, 1, rolling_date, 1)\n","    mean_monthly_return = mean_returns(stock, 12, 1, rolling_date, 1)\n","    monthly_volatility = 1/risk_adj_returns(stock, 12, 1, rolling_date, 1)*mean_monthly_return # This is not monthly volatility\n","    risk_adj_mean_return = risk_adj_returns(stock, 12, 1, rolling_date,1)\n","\n","    trades_sheet_df_r.loc[len(trades_sheet_df_r.index)] = [year, month,position, stock, buy, sell, drawdown[stock].min(), upside[stock].max(), monthly_return, cumulative_return, mean_monthly_return, monthly_volatility, risk_adj_mean_return, weight_norm.values[0]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XMFwage5jdE0"},"outputs":[],"source":["# Commented out code to create an interactive sheet for risk adjusted returns trades\n","# This is likely commented out because the sheet has already been generated\n","#sheet = sheets.InteractiveSheet(title = 'Trade Sheet Based on Risk Adjusted Returns', df=trades_sheet_df_r)"]},{"cell_type":"markdown","source":["# Create trade sheet using Volatility Trend"],"metadata":{"id":"ISEQrt8fzUHD"}},{"cell_type":"markdown","source":["\n","This cell creates a DataFrame trades_sheet_df_v to record the trade details for a long-only strategy based on volatility trend. It iterates through rolling dates, selects the top performing stocks based on volatility trend, calculates their weights, and records trade information."],"metadata":{"id":"XCk-wW10zWGV"}},{"cell_type":"code","source":["#Create trade sheet using volatility returns\n","trades_sheet_df_v = pd.DataFrame(columns = ['Year','Month','Position','stock','buy','sell', 'drawdown', 'upside', 'Monthly_Return', 'Cumulative_return', 'Mean_Monthly_Return', 'Monthly_Volatility', 'Risk_Adjusted_Mean_Return', 'Weight_norm'])\n","for rolling_date in range(12):\n","\n","  year = (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y')\n","  month = (datetime.today() - relativedelta(months= skip_period+rolling_date)).strftime('%m')\n","  stocks = return_params[return_params['Date'] == (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y-%m-%d')].sort_values(by = 'Volatility Trend', ascending = False).head()['Ticker'].values\n","\n","  weight = calculate_weights(stocks, 12, 1, rolling_date, 1)\n","\n","  weights_df = pd.DataFrame(columns = ['Ticker','Weight'])\n","\n","  for i in range(len(stocks)):\n","    weights_df.loc[len(weights_df.index)] = [stocks[i], weight[i]]\n","\n","  for stock in stocks:\n","\n","    if weight.all() > 0:\n","      position = 'Buy'\n","    else:\n","      position = 'Sell' #Safeguard, doesn't function in long only strat\n","\n","    price_data = yf.download(stock, (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y-%m-%d'),\n","                      end = (datetime.today() - relativedelta(months= skip_period+rolling_date)).strftime('%Y-%m-%d'),\n","                      auto_adjust= True, progress=False)\n","    weight_norm = weights_df.loc[weights_df['Ticker'] == stock, 'Weight']\n","\n","    drawdown = (1+price_data['Close'].pct_change()).cumprod()/((1+price_data['Close'].pct_change()).cumprod()).cummax()-1\n","    upside = (1+price_data['Close'].pct_change()).max()\n","    buy = price_data.iloc[0,0]\n","    sell = price_data.iloc[-1,0]\n","    monthly_return = log(price_data.iat[-1, 0]/price_data.iat[0, 0])*100\n","    cumulative_return = cum_returns(stock, 12, 1, rolling_date, 1)\n","    mean_monthly_return = mean_returns(stock, 12, 1, rolling_date, 1)\n","    monthly_volatility = 1/risk_adj_returns(stock, 12, 1, rolling_date, 1)*mean_monthly_return # This is not monthly volatility\n","    risk_adj_mean_return = risk_adj_returns(stock, 12, 1, rolling_date,1)\n","\n","    trades_sheet_df_v.loc[len(trades_sheet_df_v.index)] = [year, month,position, stock, buy, sell, drawdown[stock].min(), upside[stock].max(), monthly_return, cumulative_return, mean_monthly_return, monthly_volatility, risk_adj_mean_return, weight_norm.values[0]]"],"metadata":{"id":"2o0zhltOI5pe","executionInfo":{"status":"ok","timestamp":1750867660941,"user_tz":-330,"elapsed":51380,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["sheet = sheets.InteractiveSheet(title = 'Trade Sheet Based on Volatility Trend', df=trades_sheet_df_v)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":638},"id":"XMwGQxpVJTW0","executionInfo":{"status":"ok","timestamp":1750855989019,"user_tz":-330,"elapsed":2831,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"}},"outputId":"81f4ef6f-ae54-42e7-ea05-259ab1a35d7f"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["https://docs.google.com/spreadsheets/d/1WlMJhccjwjJS2sYgkKk6X6078iezB02hj7TgmMIQslE/edit#gid=0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.lib.display.IFrame at 0x7e03dc0d27d0>"],"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"600\"\n","            src=\"https://docs.google.com/spreadsheets/d/1WlMJhccjwjJS2sYgkKk6X6078iezB02hj7TgmMIQslE/edit?rm=embedded#gid=0\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"EEFM7Y2OvtvZ"},"source":["## Calculates returns over all instances of holding periods, and returns max returns and the factor used to gauge that momentum"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1750868640791,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"aNVHgvSCVExc","outputId":"feea0284-c6b8-4e64-f42d-58ff2d1319e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Max Returns Using:  Mean Returns\n","Max Returns:  36.52329284926282\n"]}],"source":["def returns_performace(trades_sheet_df):\n","  returns = np.array(trades_sheet_df['Monthly_Return'].dropna())\n","  weights = np.array(trades_sheet_df['Weight_norm'].dropna())\n","  weighted_ret = returns@weights\n","  return weighted_ret\n","\n","performance_df = pd.DataFrame(columns = ['Cumulative Returns', 'Mean Returns', 'Risk Adjusted Returns', 'Volatility Trend'])\n","performance_df.loc[len(performance_df.index)] = [returns_performace(trades_sheet_df), returns_performace(trades_sheet_df_m), returns_performace(trades_sheet_df_r), returns_performace(trades_sheet_df_v)]\n","\n","print(\"Max Returns Using: \", performance_df.iloc[0].idxmax())\n","print(\"Max Returns: \", performance_df.iloc[0].max())"]},{"cell_type":"markdown","metadata":{"id":"QHgSBrs-RMp7"},"source":["# Generates and Updates Individual Stock's Sheet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1750751548455,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"GWsPO0VPpNS9","outputId":"551c4334-a43b-45fb-d785-b87fdb20ca4a"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"if performance_df.iloc[0].idxmax() == 'Cumulative Returns':\\n  for stock in trades_sheet_df['stock']:\\n    individual_sheet = trades_sheet_df[trades_sheet_df['stock'] == stock]\\n    sheet = sheets.InteractiveSheet(title=stock+' LONG ONLY',df=individual_sheet)\\nelif performance_df.iloc[0].idxmax() == 'Mean Returns':\\n  for stock in trades_sheet_df_m['stock']:\\n    individual_sheet = trades_sheet_df_m[trades_sheet_df_m['stock'] == stock]\\n    sheet = sheets.InteractiveSheet(title=stock+' LONG ONLY',df=individual_sheet)\\nelif performance_df.iloc[0].idxmax() == 'Risk Adjusted Returns':\\n  for stock in trades_sheet_df_r['stock']:\\n    individual_sheet = trades_sheet_df_r[trades_sheet_df_r['stock'] == stock]\\n    sheet = sheets.InteractiveSheet(title=stock+' LONG ONLY',df=individual_sheet)\""]},"execution_count":120,"metadata":{},"output_type":"execute_result"}],"source":["# Commented out code to generate and update individual stock sheets based on the highest performing metric\n","'''if performance_df.iloc[0].idxmax() == 'Cumulative Returns':\n","  for stock in trades_sheet_df['stock']:\n","    individual_sheet = trades_sheet_df[trades_sheet_df['stock'] == stock]\n","    sheet = sheets.InteractiveSheet(title=stock+' LONG ONLY',df=individual_sheet)\n","elif performance_df.iloc[0].idxmax() == 'Mean Returns':\n","  for stock in trades_sheet_df_m['stock']:\n","    individual_sheet = trades_sheet_df_m[trades_sheet_df_m['stock'] == stock]\n","    sheet = sheets.InteractiveSheet(title=stock+' LONG ONLY',df=individual_sheet)\n","elif performance_df.iloc[0].idxmax() == 'Risk Adjusted Returns':\n","  for stock in trades_sheet_df_r['stock']:\n","    individual_sheet = trades_sheet_df_r[trades_sheet_df_r['stock'] == stock]\n","    sheet = sheets.InteractiveSheet(title=stock+' LONG ONLY',df=individual_sheet)\n","elif performance_df.iloc[0].idxmax() == 'Volatility Trend':\n","  for stock in trades_sheet_df_v['stock']:\n","    individual_sheet = trades_sheet_df_v[trades_sheet_df_v['stock'] == stock]'''"]},{"cell_type":"markdown","metadata":{"id":"7DmYu5KFG4aP"},"source":["# LONG SHORT STRAT"]},{"cell_type":"markdown","metadata":{"id":"32BVc0nGfL-W"},"source":["Calculates weights for long and short stocks through Hierarchial Risk Parity. The original version uses inverse variance."]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":84,"status":"ok","timestamp":1750867661165,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"O71r4GYvG_Y7"},"outputs":[],"source":["def calculate_weights_LongShort(long_tickers, short_tickers, form_period, skip_period, rolling_date, holding_period=1):\n","  weights_l = np.array([])\n","  weights_s = np.array([])\n","  weights = np.array([])\n","  for ticker in long_tickers:\n","    start = (datetime.today() - relativedelta(months= form_period+rolling_date+holding_period)).strftime('%Y-%m-%d')\n","    end = (datetime.today()-relativedelta(months = rolling_date-skip_period-holding_period)).strftime('%Y-%m-%d')\n","    price_action_l = yf.download(ticker, start, end, interval = '1mo', auto_adjust= True, progress=False)\n","\n","\n","    price_df_l = pd.DataFrame(price_action_l[('Close', ticker)])\n","\n","    returns_l = np.log(price_action_l['Close'] / price_action_l['Close'].shift(1)).dropna()\n","    returns_l.rename(columns = {ticker: 'Returns_l'}, inplace = True)\n","    std_returns_l = returns_l['Returns_l'].std()\n","\n","    weights_l = np.append(weights_l, 1/std_returns_l)\n","\n","  for ticker in short_tickers:\n","    start = (datetime.today() - relativedelta(months= form_period+rolling_date+holding_period)).strftime('%Y-%m-%d')\n","    end = (datetime.today()-relativedelta(months = rolling_date-skip_period-holding_period)).strftime('%Y-%m-%d')\n","    price_action_s = yf.download(ticker, start, end, interval = '1mo', auto_adjust= True, progress=False)\n","    price_df_s = pd.DataFrame(price_action_s[('Close', ticker)])\n","\n","    returns_s = np.log(price_action_s['Close'] / price_action_s['Close'].shift(1)).dropna()\n","    returns_s.rename(columns = {ticker: 'Returns_s'}, inplace = True)\n","    std_returns_s = -returns_s['Returns_s'].std()\n","\n","    weights_s = np.append(weights_s, 1/std_returns_s)\n","\n","  weight_n_l = weights_l/sum(weights_l)\n","  weight_n_s = -weights_s/sum(weights_s)\n","  weight_n = np.append(weight_n_l, weight_n_s)\n","  return weight_n\n","\n","# Define a function to calculate weights for long and short positions using Hierarchical Risk Parity (HRP)\n","def calculate_weights_LongShort_HRP(long_tickers, short_tickers, form_period, skip_period, rolling_date, holding_period=1):\n","    base_date = datetime.today()\n","\n","    all_tickers = list(long_tickers) + list(short_tickers)\n","    price_data = pd.DataFrame()\n","\n","    for ticker in all_tickers:\n","        start = (base_date - relativedelta(months=form_period+rolling_date+holding_period)).strftime('%Y-%m-%d')\n","        end = (base_date - relativedelta(months=rolling_date-skip_period-holding_period)).strftime('%Y-%m-%d')\n","\n","        df = yf.download(ticker, start, end, interval='1mo', auto_adjust=True, progress=False)\n","        if not df.empty:\n","            price_data[ticker] = df['Close']\n","\n","    price_data = price_data.dropna(axis=0, how='any')\n","\n","    if price_data.shape[0] < 2:\n","        return np.zeros(len(all_tickers))\n","\n","    returns = price_data.pct_change().dropna()\n","\n","    cov = returns.cov()\n","\n","    corr = returns.corr()\n","\n","    dist = np.sqrt(0.5 * (1 - corr))\n","\n","    link = linkage(squareform(dist), method='single')\n","\n","    def get_quasi_diag(link):\n","        link = link.astype(int)\n","        sort_ix = pd.Series([link[-1, 0], link[-1, 1]])\n","        num_items = link[-1, 3]\n","        while sort_ix.max() >= num_items:\n","            sort_ix.index = range(0, sort_ix.shape[0]*2, 2)\n","            df0 = sort_ix[sort_ix >= num_items]\n","            i = df0.index\n","            j = df0.values - num_items\n","            sort_ix[i] = link[j, 0]\n","            df1 = pd.Series(link[j, 1], index=i+1)\n","            sort_ix = pd.concat([sort_ix, df1])\n","            sort_ix = sort_ix.sort_index()\n","        return sort_ix.tolist()\n","\n","    sort_ix = get_quasi_diag(link)\n","    sorted_tickers = corr.columns[sort_ix]\n","\n","    def get_rec_bipart(cov, sort_ix):\n","        weights = pd.Series(1.0, index=sort_ix)\n","        cluster_items = [sort_ix]\n","\n","        while len(cluster_items) > 0:\n","            cluster_items = [i[j:k] for i in cluster_items for j,k in ((0, len(i)//2), (len(i)//2, len(i))) if len(i) > 1]\n","            for cluster in cluster_items:\n","                if len(cluster) <= 1:\n","                    continue\n","                cov_slice = cov.loc[cluster, cluster]\n","                inv_diag = 1/np.diag(cov_slice)\n","                alloc = pd.Series(inv_diag / inv_diag.sum(), index=cov_slice.index) # Ensure index is preserved\n","                cluster_var = (alloc * cov_slice @ alloc).sum()\n","                first_cluster = cluster[:len(cluster)//2]\n","                second_cluster = cluster[len(cluster)//2:]\n","                var_first = (alloc[first_cluster] * cov_slice.loc[first_cluster, first_cluster] @ alloc[first_cluster]).sum()\n","                var_second = (alloc[second_cluster] * cov_slice.loc[second_cluster, second_cluster] @ alloc[second_cluster]).sum()\n","                alpha = 1 - var_first / (var_first + var_second)\n","                weights[first_cluster] *= alpha\n","                weights[second_cluster] *= (1 - alpha)\n","\n","        return weights\n","\n","    hrp_weights = get_rec_bipart(cov, sorted_tickers)\n","\n","    long_weights = hrp_weights[long_tickers]\n","    short_weights = -hrp_weights[short_tickers]\n","\n","    long_weights /= long_weights.abs().sum()\n","    short_weights /= short_weights.abs().sum()\n","\n","    final_weights = pd.concat([long_weights, short_weights])\n","\n","    return final_weights.values\n","\n","\n","def backtest_cum_returns(long_tickers, short_tickers, form_period, skip_period, rolling_date, holding_period = 1):\n","  returns = []\n","\n","  for ticker in long_tickers:\n","    start = (datetime.today() - relativedelta(months= skip_period+rolling_date+holding_period)).strftime('%Y-%m-%d')\n","    end = (datetime.today() - relativedelta(months= rolling_date+skip_period)).strftime('%Y-%m-%d')\n","    price_action = yf.download(ticker, start, end, auto_adjust= True, progress=False)\n","    price_df = pd.DataFrame(price_action[('Close', ticker)])\n","    returns.append((price_df.iat[-1, 0]/price_df.iat[0, 0]-1)*100)\n","\n","  for ticker in short_tickers:\n","    start = (datetime.today() - relativedelta(months= skip_period+rolling_date+holding_period)).strftime('%Y-%m-%d')\n","    end = (datetime.today() - relativedelta(months= rolling_date+skip_period)).strftime('%Y-%m-%d')\n","    price_action = yf.download(ticker, start, end, auto_adjust= True, progress=False)\n","    price_df = pd.DataFrame(price_action[('Close', ticker)])\n","    returns.append(-(price_df.iat[-1, 0]/price_df.iat[0, 0]-1)*100)\n","\n","  return sum(calculate_weights_LongShort_HRP(long_tickers, short_tickers, form_period, skip_period, rolling_date, holding_period)*returns)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9068,"status":"ok","timestamp":1750867670210,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"gImd72vWAFKY","outputId":"98689e7f-ad52-4311-84b7-ad16e5421429"},"outputs":[{"output_type":"stream","name":"stdout","text":["Returns by Cumulative Stocks:  0.0826180792397605\n","Returns by Mean Stocks:  9.438206667514194\n","Returns by Risk Adjusted Stocks:  2.873169283462919\n"]}],"source":["# Calculate and print the backtested returns for the long-short strategy using different ranking metrics\n","print(\"Returns by Cumulative Stocks: \", backtest_cum_returns(top_by_cumret['Ticker'].values, bottom_by_cumret['Ticker'].values, 12, 1, 0, 1))\n","print(\"Returns by Mean Stocks: \", backtest_cum_returns(top_by_meanret['Ticker'].values, bottom_by_meanret['Ticker'].values, 12, 1, 0, 1))\n","print(\"Returns by Risk Adjusted Stocks: \", backtest_cum_returns(top_by_radret['Ticker'].values, bottom_by_radret['Ticker'].values, 12, 1, 0, 1))"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":135086,"status":"ok","timestamp":1750867805295,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"Nj-tESwZN6ns"},"outputs":[],"source":["#Create trade sheet using Cumulative Returns\n","trades = []\n","for rolling_date in range(0,12):\n","  ticker_list = pd.concat([return_params[return_params['Date'] == (datetime.today()-relativedelta(months = rolling_date+skip_period+holding_period)).strftime('%Y-%m-%d')].sort_values(by = 'Cumulative Returns', ascending = False).head(),\n","                                  return_params[return_params['Date'] == (datetime.today()-relativedelta(months = rolling_date+skip_period+holding_period)).strftime('%Y-%m-%d')].sort_values(by = 'Cumulative Returns', ascending = True).head()])\n","\n","  year = (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y')\n","  month = (datetime.today() - relativedelta(months= skip_period+rolling_date)).strftime('%m')\n","  stocks = ticker_list['Ticker'].values\n","  weight = calculate_weights_LongShort_HRP(top_by_cumret['Ticker'].values, bottom_by_cumret['Ticker'].values, 12, 1, rolling_date, 1)/2\n","  weights_df = pd.DataFrame(columns = ['Ticker','Weight'])\n","\n","  for i in range(len(stocks)):\n","    weights_df.loc[len(weights_df.index)] = [stocks[i], weight[i]]\n","  for stock in stocks:\n","    for index, row in weights_df[weights_df['Ticker']==stock].iterrows():\n","      weight_norm = row['Weight']\n","      if weight_norm > 0:\n","        position = 'Buy'\n","      else:\n","        position = 'Sell'\n","\n","    price_data = yf.download(stock, (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y-%m-%d'),\n","                        end = (datetime.today() - relativedelta(months= skip_period+rolling_date)).strftime('%Y-%m-%d'),\n","                        auto_adjust= True, progress=False)\n","\n","    drawdown = (1+price_data['Close'].pct_change()).cumprod()/((1+price_data['Close'].pct_change()).cumprod()).cummax()-1\n","    upside = (1+price_data['Close'].pct_change()).max()\n","    buy = price_data.iloc[0,0]\n","    sell = price_data.iloc[-1,0]\n","    monthly_return = log(price_data.iat[-1, 0]/price_data.iat[0, 0])*100\n","    cumulative_return = cum_returns(stock, 12, 1, rolling_date, 1)\n","    mean_monthly_return = mean_returns(stock, 12, 1, rolling_date, 1)\n","    monthly_volatility = 1/risk_adj_returns(stock, 12, 1, rolling_date, 1)*mean_monthly_return\n","    risk_adj_mean_return = risk_adj_returns(stock, 12, 1, rolling_date,1)\n","\n","    trades.append([year, month, stock, position, buy, sell, drawdown[stock].min(), upside[stock].max(), monthly_return, cumulative_return, mean_monthly_return, monthly_volatility, risk_adj_mean_return, weight_norm])\n","\n","trades_sheet_df_ls = pd.DataFrame(trades, columns = ['Year','Month','stock','position','buy','sell', 'drawdown', 'upside', 'Monthly_Return', 'Cumulative_return', 'Mean_Monthly_Return', 'Monthly_Volatility', 'Risk_Adjusted_Mean_Return', 'Weight_norm'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":638},"executionInfo":{"elapsed":1515,"status":"ok","timestamp":1750844965349,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"r8AcsCmxPGFs","outputId":"de67d345-e909-45b2-bc30-f9432774f7e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["https://docs.google.com/spreadsheets/d/1Q4iUkvdu4GyD7S2egU7iq4v82BNf_CsRQObm_ywyhUc/edit#gid=0\n"]},{"data":{"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"600\"\n","            src=\"https://docs.google.com/spreadsheets/d/1Q4iUkvdu4GyD7S2egU7iq4v82BNf_CsRQObm_ywyhUc/edit?rm=embedded#gid=0\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x7e03f02c6050>"]},"metadata":{},"output_type":"display_data"}],"source":["# Create an interactive sheet for the long-short cumulative returns trades\n","sheet = sheets.InteractiveSheet(title = 'LONG SHORT: Trade Sheet Based on Cumulative Returns', df=trades_sheet_df_ls)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":132888,"status":"ok","timestamp":1750867938145,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"MUvr6aXEa8i4"},"outputs":[],"source":["#Create trade sheet using mean returns\n","trades_m = []\n","for rolling_date in range(12):\n","  ticker_list_m = pd.concat([return_params[return_params['Date'] == (datetime.today()-relativedelta(months = rolling_date+skip_period+holding_period)).strftime('%Y-%m-%d')].sort_values(by = 'Mean Returns', ascending = False).head(),\n","                                  return_params[return_params['Date'] == (datetime.today()-relativedelta(months = rolling_date+skip_period+holding_period)).strftime('%Y-%m-%d')].sort_values(by = 'Mean Returns', ascending = True).head()])\n","  year = (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y')\n","  month = (datetime.today() - relativedelta(months= skip_period+rolling_date)).strftime('%m')\n","  stocks_m = ticker_list_m['Ticker'].values\n","  weight = calculate_weights_LongShort_HRP(top_by_meanret['Ticker'].values, bottom_by_meanret['Ticker'].values, 12, 1, rolling_date, 1)/2\n","  weights_df_m = pd.DataFrame(columns = ['Ticker','Weight'])\n","\n","  for i in range(len(stocks_m)):\n","    weights_df_m.loc[len(weights_df_m.index)] = [stocks_m[i], weight[i]]\n","  for stock in stocks_m:\n","    for index, row in weights_df_m[weights_df_m['Ticker']==stock].iterrows():\n","      weight_norm = row['Weight']\n","      if weight_norm > 0:\n","        position = 'Buy'\n","      else:\n","        position = 'Sell'\n","\n","    price_data = yf.download(stock, (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y-%m-%d'),\n","                        end = (datetime.today() - relativedelta(months= skip_period+rolling_date)).strftime('%Y-%m-%d'),\n","                        auto_adjust= True, progress=False)\n","\n","    drawdown = (1+price_data['Close'].pct_change()).cumprod()/((1+price_data['Close'].pct_change()).cumprod()).cummax()-1\n","    upside = (1+price_data['Close'].pct_change()).max()\n","    buy = price_data.iloc[0,0]\n","    sell = price_data.iloc[-1,0]\n","    monthly_return = log(price_data.iat[-1, 0]/price_data.iat[0, 0])*100\n","    cumulative_return = cum_returns(stock, 12, 1, rolling_date, 1)\n","    mean_monthly_return = mean_returns(stock, 12, 1, rolling_date, 1)\n","    monthly_volatility = 1/risk_adj_returns(stock, 12, 1, rolling_date, 1)*mean_monthly_return # This is not monthly volatility\n","    risk_adj_mean_return = risk_adj_returns(stock, 12, 1, rolling_date,1)\n","\n","    trades_m.append([year, month, stock, position, buy, sell, drawdown[stock].min(), upside[stock].max(), monthly_return, cumulative_return, mean_monthly_return, monthly_volatility, risk_adj_mean_return, weight_norm])\n","\n","trades_sheet_df_ls_m = pd.DataFrame(trades_m, columns = ['Year','Month','stock','position','buy','sell', 'drawdown', 'upside', 'Monthly_Return', 'Cumulative_return', 'Mean_Monthly_Return', 'Monthly_Volatility', 'Risk_Adjusted_Mean_Return', 'Weight_norm'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":638},"executionInfo":{"elapsed":1773,"status":"ok","timestamp":1750844967978,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"VAbvg9sabN5c","outputId":"b6061fd5-df5c-49e7-889a-1449fe1c915c"},"outputs":[{"name":"stdout","output_type":"stream","text":["https://docs.google.com/spreadsheets/d/1piCWQqquSbyBVVfA-_LTL_xMbASoQcUSs8hgrba8Lmo/edit#gid=0\n"]},{"data":{"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"600\"\n","            src=\"https://docs.google.com/spreadsheets/d/1piCWQqquSbyBVVfA-_LTL_xMbASoQcUSs8hgrba8Lmo/edit?rm=embedded#gid=0\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x7e03e73c31d0>"]},"metadata":{},"output_type":"display_data"}],"source":["# Create an interactive sheet for the long-short mean returns trades\n","sheet = sheets.InteractiveSheet(title = 'LONG SHORT: Trade Sheet Based on Mean Returns', df=trades_sheet_df_ls_m)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":128150,"status":"ok","timestamp":1750868066281,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"18O8wYbxbVmv"},"outputs":[],"source":["#Create trade sheet using Risk Adjusted Returns\n","trades_rad = []\n","for rolling_date in range(12):\n","  ticker_list = pd.concat([return_params[return_params['Date'] == (datetime.today()-relativedelta(months = rolling_date+skip_period+holding_period)).strftime('%Y-%m-%d')].sort_values(by = 'Risk Adjusted Returns', ascending = False).head(),\n","                                  return_params[return_params['Date'] == (datetime.today()-relativedelta(months = rolling_date+skip_period+holding_period)).strftime('%Y-%m-%d')].sort_values(by = 'Risk Adjusted Returns', ascending = True).head()])\n","  year = (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y')\n","  month = (datetime.today() - relativedelta(months= skip_period+rolling_date)).strftime('%m')\n","  stocks = ticker_list['Ticker'].values\n","  weight = calculate_weights_LongShort_HRP(top_by_radret['Ticker'].values, bottom_by_radret['Ticker'].values, 12, 1, rolling_date, 1)/2\n","  weights_df = pd.DataFrame(columns = ['Ticker','Weight'])\n","\n","  for i in range(len(stocks)):\n","    weights_df.loc[len(weights_df.index)] = [stocks[i], weight[i]]\n","  for stock in stocks:\n","    for index, row in weights_df[weights_df['Ticker']==stock].iterrows():\n","      weight_norm = row['Weight']\n","      if weight_norm > 0:\n","        position = 'Buy'\n","      else:\n","        position = 'Sell'\n","\n","    price_data = yf.download(stock, (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y-%m-%d'),\n","                        end = (datetime.today() - relativedelta(months= skip_period+rolling_date)).strftime('%Y-%m-%d'),\n","                        auto_adjust= True, progress=False)\n","\n","    drawdown = (1+price_data['Close'].pct_change()).cumprod()/((1+price_data['Close'].pct_change()).cumprod()).cummax()-1\n","    upside = (1+price_data['Close'].pct_change()).max()\n","    buy = price_data.iloc[0,0]\n","    sell = price_data.iloc[-1,0]\n","    monthly_return = log(price_data.iat[-1, 0]/price_data.iat[0, 0])*100\n","    cumulative_return = cum_returns(stock, 12, 1, rolling_date, 1)\n","    mean_monthly_return = mean_returns(stock, 12, 1, rolling_date, 1)\n","    monthly_volatility = 1/risk_adj_returns(stock, 12, 1, rolling_date, 1)*mean_monthly_return\n","    risk_adj_mean_return = risk_adj_returns(stock, 12, 1, rolling_date,1)\n","\n","    trades_rad.append([year, month, stock, position, buy, sell, drawdown[stock].min(), upside[stock].max(), monthly_return, cumulative_return, mean_monthly_return, monthly_volatility, risk_adj_mean_return, weight_norm])\n","\n","trades_sheet_df_ls_rad = pd.DataFrame(trades, columns = ['Year','Month','stock','position','buy','sell', 'drawdown', 'upside', 'Monthly_Return', 'Cumulative_return', 'Mean_Monthly_Return', 'Monthly_Volatility', 'Risk_Adjusted_Mean_Return', 'Weight_norm'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":638},"executionInfo":{"elapsed":1855,"status":"ok","timestamp":1750844990866,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"Ztjt7Ok0cBtj","outputId":"0d93c7d7-ce35-46d5-fab4-6b6cd902b611"},"outputs":[{"name":"stdout","output_type":"stream","text":["https://docs.google.com/spreadsheets/d/1FiuhzxOfK56GDpv0ZbcO_flGFFLpHNoa7x-uV51SxCo/edit#gid=0\n"]},{"data":{"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"600\"\n","            src=\"https://docs.google.com/spreadsheets/d/1FiuhzxOfK56GDpv0ZbcO_flGFFLpHNoa7x-uV51SxCo/edit?rm=embedded#gid=0\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x7e03f02c6050>"]},"metadata":{},"output_type":"display_data"}],"source":["# Create an interactive sheet for the long-short risk adjusted returns trades\n","sheet = sheets.InteractiveSheet(title = 'LONG SHORT: Trade Sheet Based on Risk Adjusted Returns', df=trades_sheet_df_ls_rad)"]},{"cell_type":"code","source":["#Create trade sheet using Volatility Trends\n","trades_v = []\n","for rolling_date in range(0,12):\n","  ticker_list = pd.concat([return_params[return_params['Date'] == (datetime.today()-relativedelta(months = rolling_date+skip_period+holding_period)).strftime('%Y-%m-%d')].sort_values(by = 'Volatility Trend', ascending = False).head(),\n","                                  return_params[return_params['Date'] == (datetime.today()-relativedelta(months = rolling_date+skip_period+holding_period)).strftime('%Y-%m-%d')].sort_values(by = 'Volatility Trend', ascending = True).head()])\n","\n","  year = (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y')\n","  month = (datetime.today() - relativedelta(months= skip_period+rolling_date)).strftime('%m')\n","  stocks = ticker_list['Ticker'].values\n","  weight = calculate_weights_LongShort_HRP(top_by_voltrend['Ticker'].values, bottom_by_voltrend['Ticker'].values, 12, 1, rolling_date, 1)/2\n","  weights_df = pd.DataFrame(columns = ['Ticker','Weight'])\n","\n","  for i in range(len(stocks)):\n","    weights_df.loc[len(weights_df.index)] = [stocks[i], weight[i]]\n","  for stock in stocks:\n","    for index, row in weights_df[weights_df['Ticker']==stock].iterrows():\n","      weight_norm = row['Weight']\n","      if weight_norm > 0:\n","        position = 'Buy'\n","      else:\n","        position = 'Sell'\n","\n","    price_data = yf.download(stock, (datetime.today() - relativedelta(months= holding_period+skip_period+rolling_date)).strftime('%Y-%m-%d'),\n","                        end = (datetime.today() - relativedelta(months= skip_period+rolling_date)).strftime('%Y-%m-%d'),\n","                        auto_adjust= True, progress=False)\n","\n","    drawdown = (1+price_data['Close'].pct_change()).cumprod()/((1+price_data['Close'].pct_change()).cumprod()).cummax()-1\n","    upside = (1+price_data['Close'].pct_change()).max()\n","    buy = price_data.iloc[0,0]\n","    sell = price_data.iloc[-1,0]\n","    monthly_return = log(price_data.iat[-1, 0]/price_data.iat[0, 0])*100\n","    cumulative_return = cum_returns(stock, 12, 1, rolling_date, 1)\n","    mean_monthly_return = mean_returns(stock, 12, 1, rolling_date, 1)\n","    monthly_volatility = 1/risk_adj_returns(stock, 12, 1, rolling_date, 1)*mean_monthly_return\n","    risk_adj_mean_return = risk_adj_returns(stock, 12, 1, rolling_date,1)\n","\n","    trades_v.append([year, month, stock, position, buy, sell, drawdown[stock].min(), upside[stock].max(), monthly_return, cumulative_return, mean_monthly_return, monthly_volatility, risk_adj_mean_return, weight_norm])\n","\n","trades_sheet_df_ls_v = pd.DataFrame(trades_v, columns = ['Year','Month','stock','position','buy','sell', 'drawdown', 'upside', 'Monthly_Return', 'Cumulative_return', 'Mean_Monthly_Return', 'Monthly_Volatility', 'Risk_Adjusted_Mean_Return', 'Weight_norm'])"],"metadata":{"id":"7Dg6EDN0y56G","executionInfo":{"status":"ok","timestamp":1750868287155,"user_tz":-330,"elapsed":101583,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# Create an interactive sheet for the long-short risk adjusted returns trades\n","sheet = sheets.InteractiveSheet(title = 'LONG SHORT: Trade Sheet Based on Volatility Trend', df=trades_sheet_df_ls_v)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":638},"id":"_BrxThlc1fzx","executionInfo":{"status":"ok","timestamp":1750868335134,"user_tz":-330,"elapsed":48006,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"}},"outputId":"8f9bf606-2f67-4c17-fff3-58bba31c648e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["https://docs.google.com/spreadsheets/d/1MfkrzlzjJGw1wcVbcweoH4oNVuMSTMwvDKJZQWeoM3U/edit#gid=0\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.lib.display.IFrame at 0x7c1621f706d0>"],"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"600\"\n","            src=\"https://docs.google.com/spreadsheets/d/1MfkrzlzjJGw1wcVbcweoH4oNVuMSTMwvDKJZQWeoM3U/edit?rm=embedded#gid=0\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "]},"metadata":{}}]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1750868417959,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"DIn4sHoSeIB3","outputId":"e1003770-8948-4179-f3ef-eb4a29c3ae70"},"outputs":[{"output_type":"stream","name":"stdout","text":["Max Returns Using:  Mean Returns\n","Max Returns:  23.420302323085053\n"]}],"source":["def returns_performance(trades_sheet_df):\n","  returns = np.array(trades_sheet_df['Monthly_Return'].dropna())\n","  weights = np.array(trades_sheet_df['Weight_norm'].dropna())\n","\n","  weighted_ret = returns@weights\n","  return weighted_ret\n","\n","performance_df_longshort = pd.DataFrame(columns = ['Cumulative Returns', 'Mean Returns', 'Risk Adjusted Returns', 'Volatility Trend'])\n","\n","performance_df_longshort.loc[len(performance_df_longshort.index)] = [returns_performance(trades_sheet_df_ls), returns_performance(trades_sheet_df_ls_m), returns_performance(trades_sheet_df_ls_rad), returns_performance(trades_sheet_df_ls_v)]\n","\n","print(\"Max Returns Using: \", performance_df_longshort.iloc[0].idxmax())\n","print(\"Max Returns: \", performance_df_longshort.iloc[0].max())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JlNE-S7XdVOU"},"outputs":[],"source":["# Checks for the highest performing long-short metric and produces individual sheets based on that. Commented now because sheets already generated.\n","'''if performance_df_longshort.iloc[0].idxmax() == 'Cumulative Returns':\n","  for stock in trades_sheet_df_ls['stock']:\n","    individual_sheet = trades_sheet_df_ls[trades_sheet_df_ls['stock'] == stock]\n","    sheet = sheets.InteractiveSheet(title=stock+' LONG SHORT',df=individual_sheet)\n","elif performance_df_longshort.iloc[0].idxmax() == 'Mean Returns':\n","  for stock in trades_sheet_df_ls_m['stock']:\n","    individual_sheet = trades_sheet_df_ls_m[trades_sheet_df_ls_m['stock'] == stock]\n","    sheet = sheets.InteractiveSheet(title=stock+' LONG SHORT',df=individual_sheet)\n","elif performance_df_longshort.iloc[0].idxmax() == 'Risk Adjusted Returns':\n","  for stock in trades_sheet_df_ls_rad['stock']:\n","    individual_sheet = trades_sheet_df_ls_rad[trades_sheet_df_ls_rad['stock'] == stock]\n","    sheet = sheets.InteractiveSheet(title=stock+' LONG SHORT',df=individual_sheet)\n","elif performance_df_longshort.iloc[0].idxmax() == 'Volatility Trend':\n","  for stock in trades_sheet_df_ls_v['stock']:\n","    individual_sheet = trades_sheet'''"]},{"cell_type":"markdown","metadata":{"id":"1IU4vBwCjlwc"},"source":["# Portfolio Sheet Long Only"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":123,"status":"ok","timestamp":1750868640907,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"ke1Cxg76M9Se"},"outputs":[],"source":["portfolio_rows = []\n","\n","if performance_df.iloc[0].idxmax() == 'Cumulative Returns':\n","  trades_sheet_df_final = trades_sheet_df\n","  text = ' Cumulative Returns'\n","elif performance_df.iloc[0].idxmax() == 'Mean Returns':\n","  trades_sheet_df_final = trades_sheet_df_m\n","  text = ' Mean Returns'\n","elif performance_df.iloc[0].idxmax() == 'Risk Adjusted Returns':\n","  trades_sheet_df_final = trades_sheet_df_r\n","  text = ' Risk Adjusted Returns'\n","elif performance_df.iloc[0].idxmax() == 'Volatility Trend':\n","  trades_sheet_df_final = trades_sheet_df_v\n","  text = ' Volatility Trend'\n","\n","tickers = [\"ADANIPORTS.NS\", \"ASIANPAINT.NS\", \"AXISBANK.NS\", \"BAJAJ-AUTO.NS\", \"BAJFINANCE.NS\",\n","    \"BAJAJFINSV.NS\", \"BPCL.NS\", \"BHARTIARTL.NS\", \"BRITANNIA.NS\", \"CIPLA.NS\",\n","    \"COALINDIA.NS\", \"DIVISLAB.NS\", \"DRREDDY.NS\", \"EICHERMOT.NS\", \"GRASIM.NS\",\n","    \"HCLTECH.NS\", \"HDFCBANK.NS\", \"HDFCLIFE.NS\", \"HEROMOTOCO.NS\", \"HINDALCO.NS\",\n","    \"HINDUNILVR.NS\", \"ICICIBANK.NS\", \"ITC.NS\", \"INDUSINDBK.NS\", \"INFY.NS\",\n","    \"JSWSTEEL.NS\", \"KOTAKBANK.NS\", \"LT.NS\", \"M&M.NS\", \"MARUTI.NS\",\n","    \"NTPC.NS\", \"NESTLEIND.NS\", \"ONGC.NS\", \"POWERGRID.NS\", \"RELIANCE.NS\",\n","    \"SBILIFE.NS\", \"SHREECEM.NS\", \"SBIN.NS\", \"SUNPHARMA.NS\", \"TCS.NS\",\n","    \"TATACONSUM.NS\", \"TATAMOTORS.NS\", \"TATASTEEL.NS\", \"TECHM.NS\", \"TITAN.NS\",\n","    \"ULTRACEMCO.NS\", \"UPL.NS\", \"WIPRO.NS\", \"ZEEL.NS\"]\n","for rolling_date in range(12):\n","\n","    month = (datetime.today() - relativedelta(months=skip_period+rolling_date)).strftime('%m')\n","    year = (datetime.today() - relativedelta(months=skip_period+rolling_date)).strftime('%Y')\n","\n","    monthly_trades = trades_sheet_df_final[(trades_sheet_df_final['Month'] == month) &(trades_sheet_df_final['Year'] == year)]\n","    portfolio_returns = (monthly_trades['Monthly_Return'] * monthly_trades['Weight_norm']).sum()\n","\n","    row = {\n","        'Month': month,\n","        'Year': year,\n","        'Portfolio_Returns': portfolio_returns\n","    }\n","\n","    for stock in tickers:\n","        if stock in monthly_trades['stock'].values:\n","            weight = monthly_trades.loc[monthly_trades['stock'] == stock, 'Weight_norm'].values[0]\n","        else:\n","            weight = 0\n","        row[stock] = weight\n","    portfolio_rows.append(row)\n","\n","portfolio_returns_df = pd.DataFrame(portfolio_rows)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nj_vafV3HbIN"},"outputs":[],"source":["# Commented out code to create an interactive sheet for the long-only portfolio\n","#sheet = sheets.InteractiveSheet(title = 'Portfolio Sheet' + ' Long Only', df=portfolio_returns_df)"]},{"cell_type":"markdown","metadata":{"id":"YW6sBRGcofM4"},"source":["# Portfolio Sheet Long Short"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1750868640926,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"nw8tnXcgokpC"},"outputs":[],"source":["# Initialize an empty list to store portfolio performance data for the long-short strategy\n","portfolio_rows_ls = []\n","# Determine which tradesheet DataFrame to use based on the highest performing long-short metric\n","if performance_df_longshort.iloc[0].idxmax() == 'Cumulative Returns':\n","  trades_sheet_df_final_ls = trades_sheet_df_ls\n","  text = ' Cumulative Returns'\n","elif performance_df_longshort.iloc[0].idxmax() == 'Mean Returns':\n","  trades_sheet_df_final_ls = trades_sheet_df_ls_m\n","  text = ' Mean Returns'\n","elif performance_df_longshort.iloc[0].idxmax() == 'Risk Adjusted Returns':\n","  trades_sheet_df_final_ls = trades_sheet_df_ls_rad\n","  text = ' Risk Adjusted Returns'\n","\n","# Define the list of all tickers\n","tickers = [\"ADANIPORTS.NS\", \"ASIANPAINT.NS\", \"AXISBANK.NS\", \"BAJAJ-AUTO.NS\", \"BAJFINANCE.NS\",\n","    \"BAJAJFINSV.NS\", \"BPCL.NS\", \"BHARTIARTL.NS\", \"BRITANNIA.NS\", \"CIPLA.NS\",\n","    \"COALINDIA.NS\", \"DIVISLAB.NS\", \"DRREDDY.NS\", \"EICHERMOT.NS\", \"GRASIM.NS\",\n","    \"HCLTECH.NS\", \"HDFCBANK.NS\", \"HDFCLIFE.NS\", \"HEROMOTOCO.NS\", \"HINDALCO.NS\",\n","    \"HINDUNILVR.NS\", \"ICICIBANK.NS\", \"ITC.NS\", \"INDUSINDBK.NS\", \"INFY.NS\",\n","    \"JSWSTEEL.NS\", \"KOTAKBANK.NS\", \"LT.NS\", \"M&M.NS\", \"MARUTI.NS\",\n","    \"NTPC.NS\", \"NESTLEIND.NS\", \"ONGC.NS\", \"POWERGRID.NS\", \"RELIANCE.NS\",\n","    \"SBILIFE.NS\", \"SHREECEM.NS\", \"SBIN.NS\", \"SUNPHARMA.NS\", \"TCS.NS\",\n","    \"TATACONSUM.NS\", \"TATAMOTORS.NS\", \"TATASTEEL.NS\", \"TECHM.NS\", \"TITAN.NS\",\n","    \"ULTRACEMCO.NS\", \"UPL.NS\", \"WIPRO.NS\", \"ZEEL.NS\"]\n","for rolling_date in range(12):\n","    month = (datetime.today() - relativedelta(months=skip_period+rolling_date)).strftime('%m')\n","    year = (datetime.today() - relativedelta(months=skip_period+rolling_date)).strftime('%Y')\n","\n","    monthly_trades_ls = trades_sheet_df_final_ls[(trades_sheet_df_final_ls['Month'] == month) &(trades_sheet_df_final_ls['Year'] == year)]\n","    portfolio_returns = (monthly_trades_ls['Monthly_Return'] * monthly_trades_ls['Weight_norm']).sum()\n","\n","    row = {\n","        'Month': month,\n","        'Year': year,\n","        'Portfolio_Returns': portfolio_returns\n","    }\n","\n","    for stock in tickers:\n","        if stock in monthly_trades_ls['stock'].values:\n","            weight = monthly_trades_ls.loc[monthly_trades_ls['stock'] == stock, 'Weight_norm'].values[0]\n","        else:\n","            weight = 0\n","        row[stock] = weight\n","    portfolio_rows_ls.append(row)\n","\n","portfolio_returns_df_ls = pd.DataFrame(portfolio_rows_ls)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":638},"executionInfo":{"elapsed":20054,"status":"ok","timestamp":1750844771418,"user":{"displayName":"MRIDUL PANDEY","userId":"07292526495224679479"},"user_tz":-330},"id":"Lo7TQtoLpMeO","outputId":"709bb51e-eaf0-4181-a8bc-54cf2171533e"},"outputs":[{"name":"stdout","output_type":"stream","text":["https://docs.google.com/spreadsheets/d/1VpHyKOwYeWPHViu7OeQJzXHhQXMeHwVexrNfH0vdDTM/edit#gid=0\n"]},{"data":{"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"600\"\n","            src=\"https://docs.google.com/spreadsheets/d/1VpHyKOwYeWPHViu7OeQJzXHhQXMeHwVexrNfH0vdDTM/edit?rm=embedded#gid=0\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x7e03e726a4d0>"]},"metadata":{},"output_type":"display_data"}],"source":["# Create an interactive sheet for the long-short portfolio\n","sheet = sheets.InteractiveSheet(title = 'Portfolio Sheet' + ' Long Short', df=portfolio_returns_df_ls)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNG9OdNgGvEp7AJ9tjye1Ev"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}